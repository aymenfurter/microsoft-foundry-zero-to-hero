{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eaf53ce",
   "metadata": {},
   "source": [
    "# Lab 6: Foundry IQ - Knowledge Retrieval for Agents\n",
    "\n",
    "Build an agent that answers questions about **Space Facts** using Foundry IQ!\n",
    "\n",
    "## What is Foundry IQ?\n",
    "\n",
    "| Without Foundry IQ | With Foundry IQ |\n",
    "|-------------------|----------------|\n",
    "| Embed RAG logic in every agent | Centralized knowledge retrieval |\n",
    "| Duplicate retrieval configs | Share knowledge bases across agents |\n",
    "| Manual query decomposition | Automatic query planning & synthesis |\n",
    "\n",
    "\n",
    "## Features Demonstrated\n",
    "- **APIM Gateway** - Uses central Landing Zone models (chat + embeddings)\n",
    "- **Vector Search** - Embeddings via APIM for semantic similarity\n",
    "- **Multiple knowledge sources** in one knowledge base\n",
    "- **Search index** with custom CSV data + vector embeddings\n",
    "\n",
    "## Prerequisites\n",
    "- Completed **Lab 1a** (Landing Zone with APIM + embedding model) \n",
    "- `.env` file with APIM_URL and APIM_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d117ec",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "680da5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas requests azure-ai-projects==2.0.0b2 azure-identity azure-search-documents -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0244342",
   "metadata": {},
   "source": [
    "## Step 2: Configure Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6bbf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Load .env from parent directory\n",
    "env_path = Path(\"../.env\")\n",
    "if env_path.exists():\n",
    "    for line in env_path.read_text().splitlines():\n",
    "        if '=' in line and not line.startswith('#'):\n",
    "            key, value = line.split('=', 1)\n",
    "            os.environ[key.strip()] = value.strip()\n",
    "\n",
    "# Landing Zone settings (from Lab 1a)\n",
    "APIM_URL = os.environ.get(\"APIM_URL\", \"\")\n",
    "APIM_KEY = os.environ.get(\"APIM_KEY\", \"\")\n",
    "MODEL_NAME = os.environ.get(\"MODEL_NAME\", \"gpt-4.1-mini\")\n",
    "EMBEDDING_MODEL = os.environ.get(\"EMBEDDING_MODEL\", \"text-embedding-3-large\")\n",
    "\n",
    "# Resource group for this lab\n",
    "RG = \"foundryiq-lab\"\n",
    "LOCATION = \"eastus2\"\n",
    "\n",
    "# Names for our Foundry IQ resources\n",
    "KNOWLEDGE_BASE = \"space-facts-kb\"\n",
    "\n",
    "# Get current user info\n",
    "PRINCIPAL_ID = subprocess.run(\n",
    "    'az ad signed-in-user show --query id -o tsv',\n",
    "    shell=True, capture_output=True, text=True\n",
    ").stdout.strip()\n",
    "\n",
    "SUBSCRIPTION_ID = subprocess.run(\n",
    "    'az account show --query id -o tsv',\n",
    "    shell=True, capture_output=True, text=True\n",
    ").stdout.strip()\n",
    "\n",
    "# Verify Landing Zone is configured\n",
    "if not APIM_URL or not APIM_KEY:\n",
    "    print(\"‚ùå Missing APIM_URL or APIM_KEY in .env file!\")\n",
    "    print(\"   Please complete Lab 1a first to deploy the Landing Zone\")\n",
    "else:\n",
    "    display(Markdown(f'''\n",
    "### ‚úÖ Configuration Loaded\n",
    "\n",
    "| Setting | Value |\n",
    "|---------|-------|\n",
    "| APIM Gateway | `{APIM_URL[:50]}...` |\n",
    "| Chat Model | `{MODEL_NAME}` |\n",
    "| Embedding Model | `{EMBEDDING_MODEL}` |\n",
    "| Resource Group | `{RG}` |\n",
    "| Knowledge Base | `{KNOWLEDGE_BASE}` |\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea5c4a",
   "metadata": {},
   "source": [
    "## Step 3: Create Resource Group & Deploy Spoke\n",
    "\n",
    "This creates:\n",
    "- **Azure AI Search** (for Foundry IQ knowledge bases)\n",
    "- **AI Foundry Account + Project** (uses APIM gateway - no local models!)\n",
    "- **APIM Connection** to Landing Zone\n",
    "- All necessary RBAC permissions\n",
    "\n",
    "‚è±Ô∏è ~5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1994ab79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location    Name\n",
      "----------  -------------\n",
      "eastus2     foundryiq-lab\n"
     ]
    }
   ],
   "source": [
    "!az group create -n \"{RG}\" -l \"{LOCATION}\" -o table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b809ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!az deployment group create -g \"{RG}\" --template-file spoke.bicep \\\n",
    "    -p deployerPrincipalId=\"{PRINCIPAL_ID}\" \\\n",
    "    -p apimUrl=\"{APIM_URL}\" \\\n",
    "    -p apimSubscriptionKey=\"{APIM_KEY}\" \\\n",
    "    -p gatewayModelName=\"{MODEL_NAME}\" \\\n",
    "    -o table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f18f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Get deployment outputs\n",
    "outputs = json.loads(subprocess.run(\n",
    "    f'az deployment group show -g \"{RG}\" -n spoke --query properties.outputs -o json',\n",
    "    shell=True, capture_output=True, text=True\n",
    ").stdout)\n",
    "\n",
    "ACCOUNT_NAME = outputs['accountName']['value']\n",
    "PROJECT_NAME = outputs['projectName']['value']\n",
    "PROJECT_ENDPOINT = outputs['projectEndpoint']['value']\n",
    "PROJECT_MI = outputs['projectManagedIdentityId']['value']\n",
    "APIM_CONNECTION = outputs['apimConnectionName']['value']\n",
    "SEARCH_ENDPOINT = outputs['searchEndpoint']['value']\n",
    "SEARCH_NAME = outputs['searchName']['value']\n",
    "\n",
    "# Gateway model must be in format: <connection-name>/<model-name>\n",
    "GATEWAY_MODEL = f\"{APIM_CONNECTION}/{outputs['gatewayModelName']['value']}\"\n",
    "\n",
    "display(Markdown(f'''\n",
    "### ‚úÖ Spoke Deployment Complete!\n",
    "\n",
    "| Resource | Value |\n",
    "|----------|-------|\n",
    "| AI Account | `{ACCOUNT_NAME}` |\n",
    "| Project | `{PROJECT_NAME}` |\n",
    "| APIM Connection | `{APIM_CONNECTION}` |\n",
    "| Gateway Model | `{GATEWAY_MODEL}` |\n",
    "| Search Service | `{SEARCH_NAME}` |\n",
    "\n",
    "üí° **No local model deployments** - using APIM gateway to Landing Zone!\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91c59f2",
   "metadata": {},
   "source": [
    "## Step 4: Wait for RBAC Propagation\n",
    "\n",
    "Azure role assignments can take a minute to propagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b07b180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RBAC permissions ready!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "for i in range(60, 0, -10):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"‚è≥ Waiting for RBAC to propagate... {i}s\")\n",
    "    time.sleep(10)\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(\"‚úÖ RBAC permissions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d877ee10",
   "metadata": {},
   "source": [
    "## Step 5: Create Search Index with Vector Search\n",
    "\n",
    "We'll create a search index with **vector search** capabilities and load fun space facts from a CSV file.\n",
    "\n",
    "The embedding model runs through the APIM gateway (same API key as chat completions)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4510ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Index 'space-facts' created with vector search + semantic search!\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex, SearchField, SearchFieldDataType,\n",
    "    SemanticConfiguration, SemanticField, SemanticPrioritizedFields, SemanticSearch,\n",
    "    VectorSearch, HnswAlgorithmConfiguration, VectorSearchProfile\n",
    ")\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "index_client = SearchIndexClient(endpoint=SEARCH_ENDPOINT, credential=credential)\n",
    "\n",
    "INDEX_NAME = \"space-facts\"\n",
    "\n",
    "# Create index with vector search + semantic search\n",
    "index = SearchIndex(\n",
    "    name=INDEX_NAME,\n",
    "    fields=[\n",
    "        SearchField(name=\"id\", type=\"Edm.String\", key=True, filterable=True),\n",
    "        SearchField(name=\"fact\", type=\"Edm.String\", searchable=True),\n",
    "        SearchField(name=\"category\", type=\"Edm.String\", filterable=True, facetable=True),\n",
    "        SearchField(name=\"fun_rating\", type=\"Edm.Int32\", filterable=True, sortable=True),\n",
    "        # Vector field for embeddings (text-embedding-3-large = 3072 dimensions)\n",
    "        SearchField(\n",
    "            name=\"fact_vector\", \n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            vector_search_dimensions=3072,\n",
    "            vector_search_profile_name=\"vector-profile\",\n",
    "            searchable=True\n",
    "        ),\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        algorithms=[HnswAlgorithmConfiguration(name=\"hnsw-algo\")],\n",
    "        profiles=[VectorSearchProfile(name=\"vector-profile\", algorithm_configuration_name=\"hnsw-algo\")]\n",
    "    ),\n",
    "    semantic_search=SemanticSearch(\n",
    "        default_configuration_name=\"semantic-config\",\n",
    "        configurations=[SemanticConfiguration(\n",
    "            name=\"semantic-config\",\n",
    "            prioritized_fields=SemanticPrioritizedFields(\n",
    "                content_fields=[SemanticField(field_name=\"fact\")]\n",
    "            )\n",
    "        )]\n",
    "    )\n",
    ")\n",
    "\n",
    "index_client.create_or_update_index(index)\n",
    "print(f\"‚úÖ Index '{INDEX_NAME}' created with vector search + semantic search!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a98cb9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embedding model working via APIM! Dimension: 3072\n",
      "üìö Loaded 15 space facts from CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fact</th>\n",
       "      <th>category</th>\n",
       "      <th>fun_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fact-001</td>\n",
       "      <td>A day on Venus is longer than its year! Venus ...</td>\n",
       "      <td>planets</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fact-002</td>\n",
       "      <td>Jupiter's Great Red Spot is a storm that has b...</td>\n",
       "      <td>planets</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fact-003</td>\n",
       "      <td>Saturn's rings are made mostly of ice particle...</td>\n",
       "      <td>planets</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fact-004</td>\n",
       "      <td>Neutron stars are so dense that a teaspoon of ...</td>\n",
       "      <td>stars</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fact-005</td>\n",
       "      <td>The Sun contains 99.86% of all mass in our sol...</td>\n",
       "      <td>stars</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               fact category  \\\n",
       "0  fact-001  A day on Venus is longer than its year! Venus ...  planets   \n",
       "1  fact-002  Jupiter's Great Red Spot is a storm that has b...  planets   \n",
       "2  fact-003  Saturn's rings are made mostly of ice particle...  planets   \n",
       "3  fact-004  Neutron stars are so dense that a teaspoon of ...    stars   \n",
       "4  fact-005  The Sun contains 99.86% of all mass in our sol...    stars   \n",
       "\n",
       "   fun_rating  \n",
       "0           5  \n",
       "1           5  \n",
       "2           4  \n",
       "3           5  \n",
       "4           4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "# Create embedding function using APIM gateway\n",
    "def get_embedding(text: str) -> list:\n",
    "    \"\"\"Get embedding via APIM gateway.\"\"\"\n",
    "    response = requests.post(\n",
    "        f\"{APIM_URL}/deployments/{EMBEDDING_MODEL}/embeddings?api-version=2024-10-21\",\n",
    "        headers={\"api-key\": APIM_KEY, \"Content-Type\": \"application/json\"},\n",
    "        json={\"input\": text, \"model\": EMBEDDING_MODEL}\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"data\"][0][\"embedding\"]\n",
    "\n",
    "# Test the embedding endpoint\n",
    "test_embedding = get_embedding(\"Hello space!\")\n",
    "print(f\"‚úÖ Embedding model working via APIM! Dimension: {len(test_embedding)}\")\n",
    "\n",
    "# Load space facts from CSV\n",
    "df = pd.read_csv(\"space_facts.csv\")\n",
    "print(f\"üìö Loaded {len(df)} space facts from CSV\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d9533",
   "metadata": {},
   "source": [
    "## Step 6: Upload Documents with Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e75aedae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Generating embeddings for space facts...\n",
      "  ‚úì Fact 15/15\n",
      "‚úÖ Generated embeddings for 15 facts\n",
      "‚úÖ Uploaded 15 facts with vector embeddings\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "\n",
    "# Convert CSV facts to documents with embeddings\n",
    "print(\"üîÑ Generating embeddings for space facts...\")\n",
    "documents = []\n",
    "for i, row in df.iterrows():\n",
    "    fact_text = row[\"fact\"]\n",
    "    documents.append({\n",
    "        \"id\": row[\"id\"],\n",
    "        \"fact\": fact_text,\n",
    "        \"category\": row[\"category\"],\n",
    "        \"fun_rating\": int(row[\"fun_rating\"]),\n",
    "        \"fact_vector\": get_embedding(fact_text),\n",
    "    })\n",
    "    print(f\"  ‚úì Fact {i+1}/{len(df)}\", end=\"\\r\")\n",
    "\n",
    "print(f\"\\n‚úÖ Generated embeddings for {len(df)} facts\")\n",
    "\n",
    "# Upload all documents\n",
    "with SearchIndexingBufferedSender(endpoint=SEARCH_ENDPOINT, index_name=INDEX_NAME, credential=credential) as sender:\n",
    "    sender.upload_documents(documents=documents)\n",
    "\n",
    "print(f\"‚úÖ Uploaded {len(documents)} facts with vector embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac479a6",
   "metadata": {},
   "source": [
    "## Step 7: Create Knowledge Source\n",
    "\n",
    "We'll create a knowledge source from our search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d56b7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ‚úÖ Knowledge source 'space-index-source' created!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from iq_helpers import FoundryIQClient\n",
    "from display_helpers import show_success, show_error\n",
    "\n",
    "iq = FoundryIQClient(SEARCH_ENDPOINT)\n",
    "\n",
    "# Create search index knowledge source\n",
    "INDEX_SOURCE = \"space-index-source\"\n",
    "result = iq.create_knowledge_source(\n",
    "    name=INDEX_SOURCE,\n",
    "    kind=\"searchIndex\",\n",
    "    config={\n",
    "        \"searchIndexParameters\": {\n",
    "            \"searchIndexName\": INDEX_NAME,\n",
    "            \"semanticConfigurationName\": \"semantic-config\",\n",
    "            \"sourceDataFields\": [],\n",
    "            \"searchFields\": []\n",
    "        }\n",
    "    }\n",
    ")\n",
    "if 'error' not in result:\n",
    "    show_success(f\"Knowledge source '{INDEX_SOURCE}' created!\")\n",
    "else:\n",
    "    show_error(result.get('error', 'Unknown error'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086fc4d1",
   "metadata": {},
   "source": [
    "## Step 8: Create Knowledge Base \n",
    "\n",
    "The knowledge base orchestrates retrieval from our knowledge source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "992bfa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ‚úÖ Knowledge base 'space-facts-kb' created with APIM model for reasoning!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create knowledge base with index source + APIM model for reasoning\n",
    "APIM_BASE_URL = APIM_URL.replace('/openai', '')\n",
    "\n",
    "model_config = {\n",
    "    \"kind\": \"azureOpenAI\",\n",
    "    \"azureOpenAIParameters\": {\n",
    "        \"resourceUri\": APIM_BASE_URL,\n",
    "        \"deploymentId\": MODEL_NAME,\n",
    "        \"apiKey\": APIM_KEY,\n",
    "        \"modelName\": MODEL_NAME\n",
    "    }\n",
    "}\n",
    "\n",
    "result = iq.create_knowledge_base(\n",
    "    name=KNOWLEDGE_BASE,\n",
    "    sources=[INDEX_SOURCE],\n",
    "    description=\"Space facts from curated CSV data\",\n",
    "    model_config=model_config\n",
    ")\n",
    "\n",
    "if 'error' not in result:\n",
    "    show_success(f\"Knowledge base '{KNOWLEDGE_BASE}' created with APIM model for reasoning!\")\n",
    "else:\n",
    "    show_error(result['error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a8d785",
   "metadata": {},
   "source": [
    "## Step 9: Test Direct Queries\n",
    "\n",
    "Let's query the knowledge base directly before connecting to an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e82797d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Query:** *\"What is the largest volcano in the solar system?\"*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:**\n",
       "\n",
       "[{\"ref_id\":0,\"content\":\"Mars has the largest volcano in the solar system called Olympus Mons which is about 13.6 miles high.\"},{\"ref_id\":1,\"content\":\"A year on Mercury is just 88 Earth days but a day on Mercury lasts 59 Earth days.\"},{\"ref_id\":2,\"content\":\"A day on Venus is longer than its year! Venus takes 243 Earth days to rotate once but only 225 Earth days to orbit the Sun.\"},{\"ref_id\":3,\"content\":\"Jupiter's Great Red Spot is a storm that has been raging for over 400 years and is so big that Earth could fit inside it.\"},{\"ref_id\":4,\"content\":\"Footprints on the Moon will last for millions of years because there is no wind or water to erode them.\"}]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**üìñ References:** 5 source(s) used"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from display_helpers import show_query_result\n",
    "\n",
    "# Query from CSV data\n",
    "result = iq.query_knowledge_base(KNOWLEDGE_BASE, \"What is the largest volcano in the solar system?\")\n",
    "show_query_result(\"What is the largest volcano in the solar system?\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3833f931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Query:** *\"Tell me about Jupiter's storm\"*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:**\n",
       "\n",
       "[{\"ref_id\":0,\"content\":\"Jupiter's Great Red Spot is a storm that has been raging for over 400 years and is so big that Earth could fit inside it.\"},{\"ref_id\":1,\"content\":\"The International Space Station travels at about 17500 mph completing one orbit around Earth every 90 minutes.\"},{\"ref_id\":2,\"content\":\"Neutron stars are so dense that a teaspoon of their material would weigh about 6 billion tons on Earth.\"}]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**üìñ References:** 3 source(s) used"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Another test query\n",
    "result = iq.query_knowledge_base(KNOWLEDGE_BASE, \"Tell me about Jupiter's storm\")\n",
    "show_query_result(\"Tell me about Jupiter's storm\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10373515",
   "metadata": {},
   "source": [
    "## Step 10: Create MCP Connection üîó\n",
    "\n",
    "Connect the Foundry project to the knowledge base via MCP (Model Context Protocol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff6a6a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ‚úÖ MCP connection 'space-facts-mcp' created!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from iq_helpers import create_mcp_connection\n",
    "\n",
    "CONNECTION_NAME = \"space-facts-mcp\"\n",
    "\n",
    "result = create_mcp_connection(\n",
    "    subscription_id=SUBSCRIPTION_ID,\n",
    "    resource_group=RG,\n",
    "    account_name=ACCOUNT_NAME,\n",
    "    project_name=PROJECT_NAME,\n",
    "    connection_name=CONNECTION_NAME,\n",
    "    search_endpoint=SEARCH_ENDPOINT,\n",
    "    kb_name=KNOWLEDGE_BASE\n",
    ")\n",
    "\n",
    "if 'error' not in result:\n",
    "    show_success(f\"MCP connection '{CONNECTION_NAME}' created!\")\n",
    "else:\n",
    "    show_error(f\"{result.get('error', 'Unknown error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f5032b",
   "metadata": {},
   "source": [
    "## Step 11: Create Space Expert Agent ü§ñ\n",
    "\n",
    "Now the fun part - create an agent that uses our knowledge base!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "174b2d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent 'SpaceExpert' v1 created!\n",
      "   Using model: landing-zone-apim/gpt-4.1-mini (via APIM gateway)\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import PromptAgentDefinition, MCPTool\n",
    "\n",
    "project_client = AIProjectClient(endpoint=PROJECT_ENDPOINT, credential=credential)\n",
    "\n",
    "# Build MCP endpoint URL for the knowledge base\n",
    "mcp_endpoint = f\"{SEARCH_ENDPOINT}/knowledgebases/{KNOWLEDGE_BASE}/mcp?api-version=2025-11-01-preview\"\n",
    "\n",
    "# Create the MCP tool\n",
    "mcp_tool = MCPTool(\n",
    "    server_label=\"space-facts\",\n",
    "    server_url=mcp_endpoint,\n",
    "    require_approval=\"never\",\n",
    "    allowed_tools=[\"knowledge_base_retrieve\"],\n",
    "    project_connection_id=CONNECTION_NAME\n",
    ")\n",
    "\n",
    "# Create the agent (uses APIM gateway model!)\n",
    "AGENT_NAME = \"SpaceExpert\"\n",
    "\n",
    "agent = project_client.agents.create_version(\n",
    "    agent_name=AGENT_NAME,\n",
    "    definition=PromptAgentDefinition(\n",
    "        model=GATEWAY_MODEL,\n",
    "        instructions=\"\"\"You are a knowledge retrieval agent.\n",
    "Given a query, use the MCP tool to find relevant information from the space facts knowledge base.\n",
    "\n",
    "Do not answer any questions without first consulting the MCP tool.\n",
    "\n",
    "Give detailed citations in your answers.\n",
    "\n",
    "If you can't find the answer in the mcp tool, respond with \"I don't know. \" (even if you know)\n",
    "\n",
    "Refuse to answer any queries that are not related to space.\n",
    "\"\"\",\n",
    "        tools=[mcp_tool]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Agent '{agent.name}' v{agent.version} created!\")\n",
    "print(f\"   Using model: {GATEWAY_MODEL} (via APIM gateway)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e3562",
   "metadata": {},
   "source": [
    "## Step 12: Talk to Your Space Expert! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7fafbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from display_helpers import show_agent_response\n",
    "\n",
    "openai_client = project_client.get_openai_client()\n",
    "\n",
    "def ask_space_expert(question: str):\n",
    "    \"\"\"Ask the space expert a question.\"\"\"\n",
    "    response = openai_client.responses.create(\n",
    "        input=question + \", please provide citations.\",\n",
    "        extra_body={\n",
    "            \"agent\": {\n",
    "                \"name\": agent.name, \n",
    "                \"version\": agent.version, \n",
    "                \"type\": \"agent_reference\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cb24549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "---\n",
       "**üôã You:** What's the largest storm in the solar system?\n",
       "\n",
       "**ü§ñ Agent:** The largest storm in the solar system is Jupiter's Great Red Spot. It is a massive storm that has been raging for over 400 years and is so large that Earth could fit inside it. \n",
       "\n",
       "Citation: \n",
       "- \"Jupiter‚Äôs Great Red Spot is a storm that has been raging for over 400 years and is so big that Earth could fit inside it.\" (fact-002)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ask about something from our CSV\n",
    "answer = ask_space_expert(\"What's the largest storm in the solar system?\")\n",
    "show_agent_response(\"What's the largest storm in the solar system?\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77d22aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "---\n",
       "**üôã You:** What's the largest volcano in the solar system?\n",
       "\n",
       "**ü§ñ Agent:** The largest volcano in the solar system is Olympus Mons on Mars. It stands about 13.6 miles (approximately 22 kilometers) high, making it the tallest known volcano in our solar system. \n",
       "\n",
       "Citation: \"Mars has the largest volcano in the solar system called Olympus Mons which is about 13.6 miles high.\"„Äê4:0‚Ä†source„Äë\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ask about volcanoes\n",
    "answer = ask_space_expert(\"What's the largest volcano in the solar system?\")\n",
    "show_agent_response(\"What's the largest volcano in the solar system?\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fa19f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "---\n",
       "**üôã You:** What's the capital of France?\n",
       "\n",
       "**ü§ñ Agent:** I am specialized in space-related knowledge and cannot provide information about general topics like the capital of France. If you have any questions related to space, feel free to ask!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ask something not in the knowledge base\n",
    "answer = ask_space_expert(\"What's the capital of France?\")\n",
    "show_agent_response(\"What's the capital of France?\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14d4907",
   "metadata": {},
   "source": [
    "---\n",
    "## üéâ Summary\n",
    "\n",
    "You built an AI agent with **vector search** and **APIM gateway integration** using Foundry IQ!\n",
    "\n",
    "### Architecture\n",
    "\n",
    "| Layer | Component | Purpose |\n",
    "|-------|-----------|--------|\n",
    "| **Landing Zone** | APIM Gateway | Central model access (chat + embeddings) |\n",
    "| **Landing Zone** | text-embedding-3-large | Vector embeddings via APIM |\n",
    "| **IQ Spoke** | AI Foundry Project | Agent hosting + APIM connection |\n",
    "| **IQ Spoke** | Azure AI Search | Vector index + knowledge base hosting |\n",
    "| **IQ Spoke** | Knowledge Base | Orchestrates retrieval from sources |\n",
    "| **IQ Spoke** | Knowledge Source | Index with CSV data |\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **No local model deployments** = Cost savings, central governance\n",
    "- **APIM Gateway** = Single point for model access, routing, policies\n",
    "- **Vector Search** = Embeddings via APIM for semantic similarity\n",
    "- **Foundry IQ** = Azure AI Search knowledge bases\n",
    "- **MCP** = Model Context Protocol for tool connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949147ab",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2761ff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete resources\n",
    "# iq.delete_knowledge_base(KNOWLEDGE_BASE)\n",
    "# iq.delete_knowledge_source(INDEX_SOURCE)\n",
    "# index_client.delete_index(INDEX_NAME)\n",
    "# !az group delete -n \"{RG}\" --yes --no-wait\n",
    "# print(\"üóëÔ∏è Cleanup initiated (Search service deletion takes a few minutes)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
