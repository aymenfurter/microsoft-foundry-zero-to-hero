{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e72d468",
   "metadata": {},
   "source": [
    "# Lab 5: Agent Memory \n",
    "\n",
    "Build agents with **long-term memory** using Azure AI Foundry's Memory API.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "| Scenario | Description |\n",
    "|----------|-------------|\n",
    "| **1. Memory Store** | Create stores with local models |\n",
    "| **2. Store Memories** | Extract memories from conversations |\n",
    "| **3. Scope Isolation** | Keep user data separate |\n",
    "| **4. Agent + Memory** | Agent with `memory_search` tool |\n",
    "| **5. Cross-Session** | Memory persists across sessions |\n",
    "\n",
    "## Theme: Space Exploration Expert üöÄ\n",
    "\n",
    "This lab uses a **space exploration** theme - the agent remembers users' favorite planets, space interests, and exploration preferences.\n",
    "\n",
    "\n",
    "## Prerequisites- `.env` file with `APIM_URL`, `APIM_KEY`, `MODEL_NAME`\n",
    "\n",
    "- Complete **Lab 1A** (Landing Zone) - provides APIM gateway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31e8196",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc3f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas requests azure-ai-projects==2.0.0b2 azure-identity openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e240a6",
   "metadata": {},
   "source": [
    "## Step 2: Load Landing Zone Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d226521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess, json\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Load .env file\n",
    "env_file = Path('/workspaces/getting-started-with-foundry/.env')\n",
    "if env_file.exists():\n",
    "    for line in env_file.read_text().splitlines():\n",
    "        if line.strip() and not line.startswith('#') and '=' in line:\n",
    "            key, value = line.split('=', 1)\n",
    "            os.environ[key] = value\n",
    "\n",
    "# Landing zone config\n",
    "APIM_URL = os.environ.get('APIM_URL', '')\n",
    "APIM_KEY = os.environ.get('APIM_KEY', '')\n",
    "GATEWAY_MODEL = os.environ.get('MODEL_NAME', 'gpt-4.1-mini')\n",
    "\n",
    "print(f\"‚úÖ APIM URL: {APIM_URL[:50]}...\" if APIM_URL else \"‚ùå APIM_URL not set\")\n",
    "print(f\"‚úÖ APIM Key: {APIM_KEY[:8]}...\" if APIM_KEY else \"‚ùå APIM_KEY not set\")\n",
    "print(f\"‚úÖ Gateway Model: {GATEWAY_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5e5153",
   "metadata": {},
   "source": [
    "## Step 3: Set Spoke Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "854ea040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "| Setting | Value |\n",
       "|---------|-------|\n",
       "| Resource Group | `foundry-memory-spoke` |\n",
       "| Local Chat | `gpt-4.1-mini` |\n",
       "| Embedding | `text-embedding-3-small` |\n",
       "| Memory Store | `space-expert-memory` |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Spoke configuration\n",
    "RG = \"foundry-memory-spoke\"\n",
    "LOCATION = \"eastus2\"\n",
    "LOCAL_CHAT_MODEL = \"gpt-4.1-mini\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "MEMORY_STORE_NAME = \"space-expert-memory\"\n",
    "\n",
    "PRINCIPAL_ID = subprocess.run(\n",
    "    'az ad signed-in-user show --query id -o tsv',\n",
    "    shell=True, capture_output=True, text=True\n",
    ").stdout.strip()\n",
    "\n",
    "display(Markdown(f'''\n",
    "| Setting | Value |\n",
    "|---------|-------|\n",
    "| Resource Group | `{RG}` |\n",
    "| Local Chat | `{LOCAL_CHAT_MODEL}` |\n",
    "| Embedding | `{EMBEDDING_MODEL}` |\n",
    "| Memory Store | `{MEMORY_STORE_NAME}` |\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9ac27f",
   "metadata": {},
   "source": [
    "## Step 4: Create Resource Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c1e1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location    Name\n",
      "----------  --------------------\n",
      "eastus2     foundry-memory-spoke\n"
     ]
    }
   ],
   "source": [
    "!az group create -n \"{RG}\" -l \"{LOCATION}\" -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb797b7",
   "metadata": {},
   "source": [
    "## Step 4: Deploy Spoke Infrastructure\n",
    "\n",
    "Deploys local models (for Memory API) + APIM connection. ‚è±Ô∏è ~4-5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abbd0408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KName    State      Timestamp                         Mode         ResourceGroup\n",
      "------  ---------  --------------------------------  -----------  --------------------\n",
      "spoke   Succeeded  2026-01-27T16:20:45.152305+00:00  Incremental  foundry-memory-spoke\n"
     ]
    }
   ],
   "source": [
    "!az deployment group create -g \"{RG}\" --template-file spoke.bicep \\\n",
    "    -p deployerPrincipalId=\"{PRINCIPAL_ID}\" \\\n",
    "    -p apimUrl=\"{APIM_URL}\" \\\n",
    "    -p gatewayModelName=\"{GATEWAY_MODEL}\" \\\n",
    "    -p localChatModel=\"{LOCAL_CHAT_MODEL}\" \\\n",
    "    -p embeddingModelName=\"{EMBEDDING_MODEL}\" \\\n",
    "    -p apimSubscriptionKey=\"{APIM_KEY}\" \\\n",
    "    -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362c1edf",
   "metadata": {},
   "source": [
    "## Step 6: Get Deployment Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ff97cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = json.loads(subprocess.run(\n",
    "    f'az deployment group show -g \"{RG}\" -n spoke --query properties.outputs -o json',\n",
    "    shell=True, capture_output=True, text=True\n",
    ").stdout)\n",
    "\n",
    "ACCOUNT_NAME = outputs['accountName']['value']\n",
    "PROJECT_NAME = outputs['projectName']['value']\n",
    "PROJECT_ENDPOINT = outputs['projectEndpoint']['value']\n",
    "LOCAL_CHAT = outputs['localChatModel']['value']\n",
    "EMBEDDING = outputs['embeddingModelName']['value']\n",
    "\n",
    "print(f\"‚úÖ Account: {ACCOUNT_NAME}\")\n",
    "print(f\"‚úÖ Project: {PROJECT_NAME}\")\n",
    "print(f\"‚úÖ Local Chat: {LOCAL_CHAT}\")\n",
    "print(f\"‚úÖ Embedding: {EMBEDDING}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da3dd9",
   "metadata": {},
   "source": [
    "## Step 7: Wait for RBAC Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7543824b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ready\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "for i in range(60, 0, -10):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"‚è≥ RBAC propagation... {i}s\")\n",
    "    time.sleep(10)\n",
    "clear_output(wait=True)\n",
    "print(\"‚úÖ Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a921a2c0",
   "metadata": {},
   "source": [
    "## Step 8a: Setup Project Client\n",
    "\n",
    "Use the SDK for clean Responses API access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68723d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "project_client = AIProjectClient(endpoint=PROJECT_ENDPOINT, credential=credential)\n",
    "openai_client = project_client.get_openai_client()\n",
    "\n",
    "print(f\"‚úÖ Project client ready: {PROJECT_ENDPOINT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a980361d",
   "metadata": {},
   "source": [
    "## Step 8b: Setup Memory Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95b8cce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Memory client ready\n"
     ]
    }
   ],
   "source": [
    "from memory_helpers import MemoryClient, build_conversation\n",
    "from display_helpers import show_store_created, show_memories, show_search_results, show_agent_created, show_conversation, show_error\n",
    "\n",
    "memory = MemoryClient(ACCOUNT_NAME, PROJECT_NAME)\n",
    "print(f\"‚úÖ Memory client ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043cff62",
   "metadata": {},
   "source": [
    "---\n",
    "# Scenario 1: Create Memory Store\n",
    "\n",
    "The memory store uses **local models** for internal processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c10cff67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Memory Store Created"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f28b9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_f28b9_level0_col0\" class=\"col_heading level0 col0\" >Property</th>\n",
       "      <th id=\"T_f28b9_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_f28b9_row0_col0\" class=\"data row0 col0\" >Name</td>\n",
       "      <td id=\"T_f28b9_row0_col1\" class=\"data row0 col1\" >space-expert-memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f28b9_row1_col0\" class=\"data row1 col0\" >Chat Model</td>\n",
       "      <td id=\"T_f28b9_row1_col1\" class=\"data row1 col1\" >gpt-4.1-mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f28b9_row2_col0\" class=\"data row2 col0\" >Embedding Model</td>\n",
       "      <td id=\"T_f28b9_row2_col1\" class=\"data row2 col1\" >text-embedding-3-small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f28b9_row3_col0\" class=\"data row3 col0\" >Status</td>\n",
       "      <td id=\"T_f28b9_row3_col1\" class=\"data row3 col1\" >‚úÖ Created</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff3c9ede80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = memory.create_store(\n",
    "    name=MEMORY_STORE_NAME,\n",
    "    chat_model=LOCAL_CHAT,\n",
    "    embedding_model=EMBEDDING,\n",
    "    description=\"Space exploration preferences and conversation history\",\n",
    "    user_profile_details=\"Favorite planets, space missions, exploration interests, celestial phenomena preferences\"\n",
    ")\n",
    "\n",
    "if 'error' not in result:\n",
    "    show_store_created(MEMORY_STORE_NAME, LOCAL_CHAT, EMBEDDING)\n",
    "else:\n",
    "    show_error(result['error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c97e1",
   "metadata": {},
   "source": [
    "---\n",
    "# Scenario 2: Store User Memories\n",
    "\n",
    "Extract and store memories from conversations using the Memory API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f38ab17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "| User | Scope ID | Profile |\n",
       "|------|----------|---------|\n",
       "| Alice | `user_alice_123` | Loves Mars, interested in rover missions, wants to see the northern lights |\n",
       "| Bob | `user_bob_456` | Saturn fan, fascinated by rings and moons, dreams of Europa exploration |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test users with different space exploration profiles\n",
    "USER_ALICE = \"user_alice_123\"\n",
    "USER_BOB = \"user_bob_456\"\n",
    "\n",
    "display(Markdown('''\n",
    "| User | Scope ID | Profile |\n",
    "|------|----------|---------|\n",
    "| Alice | `user_alice_123` | Loves Mars, interested in rover missions, wants to see the northern lights |\n",
    "| Bob | `user_bob_456` | Saturn fan, fascinated by rings and moons, dreams of Europa exploration |\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcbe7892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Processing Alice's memories...\n",
      "‚úÖ Alice's Memories Stored - No new memories extracted\n"
     ]
    }
   ],
   "source": [
    "# Store Alice's preferences\n",
    "alice_msgs = build_conversation(\n",
    "    \"Mars is my absolute favorite planet! I'm fascinated by the Perseverance rover and Ingenuity helicopter missions. I also really want to see the northern lights on Earth someday - they're on my bucket list.\",\n",
    "    \"Got it! Mars is your favorite, you love the rover missions, and you're dreaming of seeing the aurora borealis. I'll remember that!\"\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Processing Alice's memories...\")\n",
    "result = memory.update_memories(MEMORY_STORE_NAME, USER_ALICE, alice_msgs)\n",
    "\n",
    "if 'error' not in result:\n",
    "    show_memories(\"Alice's Memories Stored\", result.get('memories', []))\n",
    "else:\n",
    "    show_error(result['error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99ec45c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Processing Bob's memories...\n",
      "‚úÖ Bob's Memories Stored - No new memories extracted\n"
     ]
    }
   ],
   "source": [
    "# Store Bob's preferences\n",
    "bob_msgs = build_conversation(\n",
    "    \"Saturn is definitely my favorite - those rings are just spectacular! I'm really interested in its moon Europa and the possibility of life in its subsurface ocean. I also love following the James Webb telescope discoveries.\",\n",
    "    \"Saturn fan with a love for those iconic rings! You're curious about Europa's ocean and following JWST discoveries. Got it!\"\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Processing Bob's memories...\")\n",
    "result = memory.update_memories(MEMORY_STORE_NAME, USER_BOB, bob_msgs)\n",
    "\n",
    "if 'error' not in result:\n",
    "    show_memories(\"Bob's Memories Stored\", result.get('memories', []))\n",
    "else:\n",
    "    show_error(result['error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dcd8de",
   "metadata": {},
   "source": [
    "---\n",
    "# Scenario 3: Search Memories (Scope Isolation)\n",
    "\n",
    "Verify each user only sees their own memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb0552ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Query:** \"Which planet should I learn more about?\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üë© Alice's Memories"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_2c5c1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_2c5c1_level0_col0\" class=\"col_heading level0 col0\" >Type</th>\n",
       "      <th id=\"T_2c5c1_level0_col1\" class=\"col_heading level0 col1\" >Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_2c5c1_row0_col0\" class=\"data row0 col0\" >user_profile</td>\n",
       "      <td id=\"T_2c5c1_row0_col1\" class=\"data row0 col1\" >User's favorite planet is Mars.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2c5c1_row1_col0\" class=\"data row1 col0\" >user_profile</td>\n",
       "      <td id=\"T_2c5c1_row1_col1\" class=\"data row1 col1\" >User has a bucket list goal to see the northern lights (aurora borealis) on Earth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2c5c1_row2_col0\" class=\"data row2 col0\" >user_profile</td>\n",
       "      <td id=\"T_2c5c1_row2_col1\" class=\"data row2 col1\" >User is fascinated by Mars rover missions, especially Perseverance and Ingenuity.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff3c8b47d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üë® Bob's Memories"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4c5fe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_4c5fe_level0_col0\" class=\"col_heading level0 col0\" >Type</th>\n",
       "      <th id=\"T_4c5fe_level0_col1\" class=\"col_heading level0 col1\" >Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_4c5fe_row0_col0\" class=\"data row0 col0\" >user_profile</td>\n",
       "      <td id=\"T_4c5fe_row0_col1\" class=\"data row0 col1\" >User's favorite planet is Saturn, with a special appreciation for its rings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4c5fe_row1_col0\" class=\"data row1 col0\" >user_profile</td>\n",
       "      <td id=\"T_4c5fe_row1_col1\" class=\"data row1 col1\" >User is interested in Europa's subsurface ocean and the potential for extraterrestrial life there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4c5fe_row2_col0\" class=\"data row2 col0\" >user_profile</td>\n",
       "      <td id=\"T_4c5fe_row2_col1\" class=\"data row2 col1\" >User follows discoveries from the James Webb Space Telescope (JWST).</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff3c8b4910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "‚úÖ **Scope isolation verified** - each user sees only their own memories"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Which planet should I learn more about?\"\n",
    "display(Markdown(f'**Query:** \"{query}\"'))\n",
    "\n",
    "# Each user only sees their own memories\n",
    "alice_result = memory.search_memories(MEMORY_STORE_NAME, USER_ALICE, query)\n",
    "bob_result = memory.search_memories(MEMORY_STORE_NAME, USER_BOB, query)\n",
    "\n",
    "show_search_results(\"Alice\", \"üë©\", alice_result.get('memories', []))\n",
    "show_search_results(\"Bob\", \"üë®\", bob_result.get('memories', []))\n",
    "\n",
    "display(Markdown('‚úÖ **Scope isolation verified** - each user sees only their own memories'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a474a9",
   "metadata": {},
   "source": [
    "---\n",
    "# Scenario 4: Agent with Memory\n",
    "\n",
    "Create an agent that uses `memory_search` tool.\n",
    "\n",
    "> ‚ö†Ô∏è **Current Limitation**: The `memory_search` tool is **not supported with BYO (gateway) models**.\n",
    "> Error: `\"The following tools are not supported with BYO model: memory_search. Please remove these tools or use a standard model deployment.\"`\n",
    "> \n",
    "> **Workaround**: Use a local model deployment for agents with memory tools.\n",
    "> Once this limitation is lifted, you can switch back to gateway models (`connection/model` format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f63eb335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Agents Created\n",
       "| User | Agent Version | Memory Scope |\n",
       "|------|--------------|--------------|\n",
       "| Alice | `16` | `user_alice_123` |\n",
       "| Bob | `17` | `user_bob_456` |\n",
       "\n",
       "> ‚ö†Ô∏è Using local model (gateway not supported with `memory_search`)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "\n",
    "AGENT_NAME = \"SpaceExpert\"\n",
    "\n",
    "def create_agent_for_user(scope: str) -> tuple:\n",
    "    \"\"\"Create an agent scoped to a specific user.\"\"\"\n",
    "    agent = project_client.agents.create_version(\n",
    "        agent_name=AGENT_NAME,\n",
    "        definition=PromptAgentDefinition(\n",
    "            model=LOCAL_CHAT,\n",
    "            instructions=\"You are a friendly space exploration expert. Personalize recommendations based on user's favorite planets and space interests. Remember their specific interests in missions, phenomena, and celestial bodies. Always use the memory tool before giving an answer.\",\n",
    "            tools=[{\n",
    "                \"type\": \"memory_search\",\n",
    "                \"memory_store_name\": MEMORY_STORE_NAME,\n",
    "                \"scope\": scope,\n",
    "                \"update_delay\": 1\n",
    "            }]\n",
    "        )\n",
    "    )\n",
    "    return agent\n",
    "\n",
    "# Create agents for each user\n",
    "agent_alice = create_agent_for_user(USER_ALICE)\n",
    "agent_bob = create_agent_for_user(USER_BOB)\n",
    "\n",
    "display(Markdown('''\n",
    "### Agents Created\n",
    "| User | Agent Version | Memory Scope |\n",
    "|------|--------------|--------------|\n",
    "| Alice | `''' + agent_alice.version + '''` | `user_alice_123` |\n",
    "| Bob | `''' + agent_bob.version + '''` | `user_bob_456` |\n",
    "\n",
    "> ‚ö†Ô∏è Using local model (gateway not supported with `memory_search`)\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3285087e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Query:** \"Hi! I want to learn something fascinating about space today. What would you recommend based on my interests?\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üë© Alice's Recommendation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c5778_row0_col0, #T_c5778_row0_col1, #T_c5778_row1_col0, #T_c5778_row1_col1 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c5778\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_c5778_level0_col0\" class=\"col_heading level0 col0\" >Role</th>\n",
       "      <th id=\"T_c5778_level0_col1\" class=\"col_heading level0 col1\" >Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_c5778_row0_col0\" class=\"data row0 col0\" >üë§ User</td>\n",
       "      <td id=\"T_c5778_row0_col1\" class=\"data row0 col1\" >Hi! I want to learn something fascinating about space today. What would you recommend based on my interests?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c5778_row1_col0\" class=\"data row1 col0\" >ü§ñ Agent</td>\n",
       "      <td id=\"T_c5778_row1_col1\" class=\"data row1 col1\" >Since you love Mars and are fascinated by the Perseverance rover and Ingenuity helicopter, here‚Äôs something fascinating: Did you know that Perseverance carries a special instrument called MOXIE (Mars Oxygen In-Situ Resource Utilization Experiment)? MOXIE is designed to produce oxygen from the thin Martian atmosphere, which is mostly carbon dioxide. This is a groundbreaking step toward enabling future human missions on Mars, as it could allow astronauts to create breathable air and rocket fuel directly on the planet!\n",
       "\n",
       "Also, tying to your bucket list interest in the aurora borealis, Mars has its own version of auroras‚Äîbut they are quite different from Earth‚Äôs. Mars‚Äô auroras are more localized and appear in patches because Mars lacks a global magnetic field like Earth does. These Martian auroras glow in ultraviolet light and were discovered by the MAVEN spacecraft studying the Martian atmosphere.\n",
       "\n",
       "Would you like to hear more about the latest findings from Perseverance or how Ingenuity‚Äôs flights are helping us explore Mars? Or maybe more about Martian auroras?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff3c1dd6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üë® Bob's Recommendation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1f1ef_row0_col0, #T_1f1ef_row0_col1, #T_1f1ef_row1_col0, #T_1f1ef_row1_col1 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1f1ef\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_1f1ef_level0_col0\" class=\"col_heading level0 col0\" >Role</th>\n",
       "      <th id=\"T_1f1ef_level0_col1\" class=\"col_heading level0 col1\" >Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_1f1ef_row0_col0\" class=\"data row0 col0\" >üë§ User</td>\n",
       "      <td id=\"T_1f1ef_row0_col1\" class=\"data row0 col1\" >Hi! I want to learn something fascinating about space today. What would you recommend based on my interests?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_1f1ef_row1_col0\" class=\"data row1 col0\" >ü§ñ Agent</td>\n",
       "      <td id=\"T_1f1ef_row1_col1\" class=\"data row1 col1\" >Since you love Saturn and its iconic rings, and have a keen interest in Europa's subsurface ocean and the possibility of life there, plus you follow discoveries from the James Webb Space Telescope (JWST), I have a fascinating space tidbit for you:\n",
       "\n",
       "Recently, JWST has been providing incredibly detailed infrared observations that can help scientists understand the composition of icy moons and gas giants. While Europa is a moon of Jupiter (not Saturn), JWST's spectroscopic capabilities allow us to study the surface ices and possible plumes on Europa, searching for organic molecules or signs of habitability hidden beneath its icy shell.\n",
       "\n",
       "Additionally, Saturn‚Äôs rings themselves continue to surprise us. JWST‚Äôs infrared observations help scientists analyze the composition of Saturn's rings, revealing how their particles might age and interact with Saturn‚Äôs magnetosphere. This gives clues about the rings‚Äô origins and their dynamic changes over time.\n",
       "\n",
       "Would you like me to share the latest findings from JWST about Saturn‚Äôs rings or recent intriguing studies related to Europa‚Äôs ocean and potential biosignatures?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff3c1dd590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "### ‚úÖ Same query, different answers!\n",
       "- **Alice** gets Mars/rover mission recommendations (loves Mars and Perseverance)\n",
       "- **Bob** gets Saturn/Europa recommendations (fascinated by rings and subsurface oceans)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Hi! I want to learn something fascinating about space today. What would you recommend based on my interests?\"\n",
    "display(Markdown(f'**Query:** \"{query}\"'))\n",
    "\n",
    "# Alice's recommendation\n",
    "response_alice = openai_client.responses.create(\n",
    "    input=query,\n",
    "    extra_body={\"agent\": {\"name\": agent_alice.name, \"version\": agent_alice.version, \"type\": \"agent_reference\"}}\n",
    ")\n",
    "alice_response = response_alice.output_text if hasattr(response_alice, 'output_text') else str(response_alice.output)\n",
    "\n",
    "# Bob's recommendation\n",
    "response_bob = openai_client.responses.create(\n",
    "    input=query,\n",
    "    extra_body={\"agent\": {\"name\": agent_bob.name, \"version\": agent_bob.version, \"type\": \"agent_reference\"}}\n",
    ")\n",
    "bob_response = response_bob.output_text if hasattr(response_bob, 'output_text') else str(response_bob.output)\n",
    "\n",
    "display(Markdown('---'))\n",
    "show_conversation(\"üë© Alice's Recommendation\", query, alice_response)\n",
    "display(Markdown('---'))\n",
    "show_conversation(\"üë® Bob's Recommendation\", query, bob_response)\n",
    "\n",
    "display(Markdown('''\n",
    "### ‚úÖ Same query, different answers!\n",
    "- **Alice** gets Mars/rover mission recommendations (loves Mars and Perseverance)\n",
    "- **Bob** gets Saturn/Europa recommendations (fascinated by rings and subsurface oceans)\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47aa57f",
   "metadata": {},
   "source": [
    "---\n",
    "# Scenario 5: Automatic Memory Extraction\n",
    "\n",
    "Demonstrate that the agent **automatically learns** from conversations - no manual `update_memories()` needed!\n",
    "\n",
    "> üìù **How it works:**\n",
    "> - The `memory_search` tool has `update_delay` set (we use 1 second for demo)\n",
    "> - After each response, the system automatically extracts memories\n",
    "> - Chat summaries are enabled in our memory store (`chat_summary_enabled: True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "834abbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_CHARLIE = \"user_charlie_789\"\n",
    "agent_charlie = create_agent_for_user(USER_CHARLIE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa634cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Turn 1: Charlie chats with the agent"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Charlie's First Message"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b6469_row0_col0, #T_b6469_row0_col1, #T_b6469_row1_col0, #T_b6469_row1_col1 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b6469\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_b6469_level0_col0\" class=\"col_heading level0 col0\" >Role</th>\n",
       "      <th id=\"T_b6469_level0_col1\" class=\"col_heading level0 col1\" >Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_b6469_row0_col0\" class=\"data row0 col0\" >üë§ Charlie</td>\n",
       "      <td id=\"T_b6469_row0_col1\" class=\"data row0 col1\" >Hi! I'm really excited about the upcoming solar eclipse next month. I want to find the best viewing spot and learn about what causes them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b6469_row1_col0\" class=\"data row1 col0\" >ü§ñ Agent</td>\n",
       "      <td id=\"T_b6469_row1_col1\" class=\"data row1 col1\" >That's awesome! Solar eclipses are incredible celestial events. They occur when the Moon passes between the Earth and the Sun, temporarily blocking out the Sun's light either partially or completely for viewers in the path.\n",
       "\n",
       "For the best viewing spot, it's important to be within the path of totality where the total eclipse is visible. The exact path changes with each eclipse. If you tell me your location or where you're willing to travel, I can help identify the most optimal viewing spots for the upcoming eclipse next month. Also, make sure to use proper eye protection like eclipse glasses to safely enjoy the event! Would you like me to recommend some safe viewing gear too?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff3c1dd590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Charlie's Second Message"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2dcce_row0_col0, #T_2dcce_row0_col1, #T_2dcce_row1_col0, #T_2dcce_row1_col1 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2dcce\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_2dcce_level0_col0\" class=\"col_heading level0 col0\" >Role</th>\n",
       "      <th id=\"T_2dcce_level0_col1\" class=\"col_heading level0 col1\" >Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_2dcce_row0_col0\" class=\"data row0 col0\" >üë§ Charlie</td>\n",
       "      <td id=\"T_2dcce_row0_col1\" class=\"data row0 col1\" >That sounds great! By the way, Jupiter is my favorite planet. I love learning about the Great Red Spot and the Galilean moons.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2dcce_row1_col0\" class=\"data row1 col0\" >ü§ñ Agent</td>\n",
       "      <td id=\"T_2dcce_row1_col1\" class=\"data row1 col1\" >Jupiter is an incredible favorite! The Great Red Spot is such a fascinating storm‚Äîit's been raging for centuries and is so massive that it could swallow Earth whole. The Galilean moons‚ÄîIo, Europa, Ganymede, and Callisto‚Äîare equally amazing, each with unique characteristics like volcanic activity on Io and the potential subsurface ocean on Europa.\n",
       "\n",
       "If you're interested, I can share updates on missions studying Jupiter and its moons, like NASA's Juno probe or the upcoming Europa Clipper mission focused on Europa's habitability. Would you like to know more about these missions or some intriguing phenomena on Jupiter and its moons?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff3c1dd590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown('### Turn 1: Charlie chats with the agent'))\n",
    "\n",
    "charlie_msg1 = \"Hi! I'm really excited about the upcoming solar eclipse next month. I want to find the best viewing spot and learn about what causes them.\"\n",
    "\n",
    "response1 = openai_client.responses.create(\n",
    "    input=charlie_msg1,\n",
    "    extra_body={\"agent\": {\"name\": agent_charlie.name, \"version\": agent_charlie.version, \"type\": \"agent_reference\"}}\n",
    ")\n",
    "charlie_response1 = response1.output_text if hasattr(response1, 'output_text') else str(response1.output)\n",
    "\n",
    "show_conversation(\"Charlie's First Message\", charlie_msg1, charlie_response1, \"Charlie\")\n",
    "\n",
    "# Continue the conversation\n",
    "charlie_msg2 = \"That sounds great! By the way, Jupiter is my favorite planet. I love learning about the Great Red Spot and the Galilean moons.\"\n",
    "\n",
    "response2 = openai_client.responses.create(\n",
    "    input=charlie_msg2,\n",
    "    extra_body={\"agent\": {\"name\": agent_charlie.name, \"version\": agent_charlie.version, \"type\": \"agent_reference\"}}\n",
    ")\n",
    "charlie_response2 = response2.output_text if hasattr(response2, 'output_text') else str(response2.output)\n",
    "\n",
    "display(Markdown('---'))\n",
    "show_conversation(\"Charlie's Second Message\", charlie_msg2, charlie_response2, \"Charlie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e9b8965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Memory extraction should be complete\n"
     ]
    }
   ],
   "source": [
    "# Wait for automatic memory extraction\n",
    "display(Markdown('### ‚è≥ Waiting for automatic memory extraction...'))\n",
    "display(Markdown('> The `memory_search` tool automatically extracts and stores memories after `update_delay` seconds of inactivity.'))\n",
    "\n",
    "import time\n",
    "for i in range(30, 0, -10):\n",
    "    clear_output(wait=True)\n",
    "    display(Markdown(f'### ‚è≥ Waiting for memory extraction... {i}s'))\n",
    "    time.sleep(10)\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(\"‚úÖ Memory extraction should be complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94d1846e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Turn 2: New conversation - test if agent remembers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Charlie Asks About Previous Chat"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c9bb1_row0_col0, #T_c9bb1_row0_col1, #T_c9bb1_row1_col0, #T_c9bb1_row1_col1 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c9bb1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_c9bb1_level0_col0\" class=\"col_heading level0 col0\" >Role</th>\n",
       "      <th id=\"T_c9bb1_level0_col1\" class=\"col_heading level0 col1\" >Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_c9bb1_row0_col0\" class=\"data row0 col0\" >üë§ Charlie</td>\n",
       "      <td id=\"T_c9bb1_row0_col1\" class=\"data row0 col1\" >What have we recently been talking about?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c9bb1_row1_col0\" class=\"data row1 col0\" >ü§ñ Agent</td>\n",
       "      <td id=\"T_c9bb1_row1_col1\" class=\"data row1 col1\" >Hey! We've recently been chatting about your excitement for the upcoming solar eclipse in February 2026. You were curious about the causes of solar eclipses‚Äîhow the Moon blocks the Sun's light when it passes between Earth and the Sun, creating the eclipse for those in the path of totality. We also talked about finding the best spots to view this amazing event and the importance of using proper eye protection.\n",
       "\n",
       "Alongside that, you've shared your love for Jupiter, especially the Great Red Spot and its fascinating Galilean moons‚ÄîI‚Äôve told you about the storm‚Äôs massive size and longevity, and unique features of moons like Io and Europa. If you want, I can keep you updated on missions like Juno and Europa Clipper too!\n",
       "\n",
       "Would you like me to help you pick some ideal places to watch the eclipse or dive back into Jupiter‚Äôs wonders?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff3bd7ca50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "### ‚úÖ Automatic Memory Extraction Works!\n",
       "\n",
       "**What just happened:**\n",
       "1. Charlie chatted about solar eclipses & Jupiter being their favorite planet\n",
       "2. We did **NOT** call `update_memories()` manually\n",
       "3. The `memory_search` tool automatically extracted and stored the conversation\n",
       "4. In a new conversation, the agent remembers what we discussed!\n",
       "\n",
       "**This is the magic of the `memory_search` tool** - it handles extraction automatically.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Turn 2: New conversation - ask what we talked about\n",
    "display(Markdown('### Turn 2: New conversation - test if agent remembers'))\n",
    "\n",
    "charlie_msg3 = \"What have we recently been talking about?\"\n",
    "\n",
    "response3 = openai_client.responses.create(\n",
    "    input=charlie_msg3,\n",
    "    extra_body={\"agent\": {\"name\": agent_charlie.name, \"version\": agent_charlie.version, \"type\": \"agent_reference\"}}\n",
    ")\n",
    "charlie_response3 = response3.output_text if hasattr(response3, 'output_text') else str(response3.output)\n",
    "\n",
    "show_conversation(\"Charlie Asks About Previous Chat\", charlie_msg3, charlie_response3, \"Charlie\")\n",
    "\n",
    "display(Markdown('''\n",
    "### ‚úÖ Automatic Memory Extraction Works!\n",
    "\n",
    "**What just happened:**\n",
    "1. Charlie chatted about solar eclipses & Jupiter being their favorite planet\n",
    "2. We did **NOT** call `update_memories()` manually\n",
    "3. The `memory_search` tool automatically extracted and stored the conversation\n",
    "4. In a new conversation, the agent remembers what we discussed!\n",
    "\n",
    "**This is the magic of the `memory_search` tool** - it handles extraction automatically.\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86101d7",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "## Key Learnings\n",
    "\n",
    "| Concept | Detail |\n",
    "|---------|--------|\n",
    "| Memory API Models | Must be deployed **locally** (not via gateway) |\n",
    "| Agent with `memory_search` | Also requires local model |\n",
    "| Token Audience | `https://ai.azure.com` |\n",
    "| Responses API | `openai_client.responses.create()` with `agent_reference` |\n",
    "\n",
    "## Current Limitation\n",
    "\n",
    "> ‚ö†Ô∏è **`memory_search` tool does not support BYO (gateway) models**\n",
    "> \n",
    "> Error: `\"The following tools are not supported with BYO model: memory_search\"`\n",
    "\n",
    "## Files\n",
    "\n",
    "| File | Purpose |\n",
    "|------|---------|\n",
    "| `memory_helpers.py` | `MemoryClient` class, `build_conversation()` |\n",
    "| `display_helpers.py` | Display functions for tables and results |\n",
    "| `spoke.bicep` | Infrastructure (local models + APIM connection) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9e29048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete all resources\n",
    "# !az group delete -n \"{RG}\" --yes --no-wait\n",
    "# print(f\"üóëÔ∏è Deleting resource group: {RG}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
